import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error, make_scorer
import joblib

# Cargar los datos
data = pd.read_csv('cves_actualizados.csv')

# Diccionarios de mapeo para CVSS 2.0 y 3.1
cvss_mapping_2_0 = {
    'AV:N': 1.0, 'AV:A': 0.646, 'AV:L': 0.395,
    'AC:L': 0.71, 'AC:M': 0.61, 'AC:H': 0.35,
    'Au:M': 0.45, 'Au:S': 0.56, 'Au:N': 0.704,
    'C:C': 0.66, 'C:P': 0.275, 'C:N': 0.0,
    'I:C': 0.66, 'I:P': 0.275, 'I:N': 0.0,
    'A:C': 0.66, 'A:P': 0.275, 'A:N': 0.0
}

cvss_mapping_3_1 = {
    'AV:N': 0.85, 'AV:A': 0.62, 'AV:L': 0.55, 'AV:P': 0.2,
    'AC:L': 0.77, 'AC:H': 0.44,
    'PR:N': 0.85, 'PR:L': 0.62, 'PR:H': 0.27,
    'UI:N': 0.85, 'UI:R': 0.62,
    'S:U': 0.77, 'S:C': 1.0,
    'C:H': 0.56, 'C:L': 0.22, 'C:N': 0.0,
    'I:H': 0.56, 'I:L': 0.22, 'I:N': 0.0,
    'A:H': 0.56, 'A:L': 0.22, 'A:N': 0.0
}

# Función para convertir los vectores CVSS a valores numéricos
def map_cvss_vector(cvss_vector, mapping):
    if pd.isna(cvss_vector):
        return []
    components = cvss_vector.split('/')
    mapped_values = []
    for comp in components:
        key_value = comp.split(':')
        if len(key_value) == 2:
            key, value = key_value
            if f"{key}:{value}" in mapping:
                mapped_values.append(mapping[f"{key}:{value}"])
            elif value in mapping:
                mapped_values.append(mapping[value])
    return mapped_values

# Aplicar el mapeo a los vectores CVSS
data['CVSS 2.0 Vector Mapped'] = data['CVSS 2.0 Vector'].apply(lambda x: map_cvss_vector(x, cvss_mapping_2_0))
data['CVSS 3.1 Vector Mapped'] = data['CVSS 3.1 Vector'].apply(lambda x: map_cvss_vector(x, cvss_mapping_3_1))

# Verificar los primeros registros para confirmar el mapeo correcto
print(data[['CVE ID', 'CVSS 2.0 Vector', 'CVSS 2.0 Vector Mapped', 'CVSS 3.1 Vector', 'CVSS 3.1 Vector Mapped']].head())

# Filtrar los datos y convertir las listas mapeadas a DataFrame
data_filtered = data[(data['CVSS 2.0 Vector Mapped'].str.len() > 0) & (data['CVSS 3.1 Vector Mapped'].str.len() > 0)]
cvss_2_0_df = pd.DataFrame(data_filtered['CVSS 2.0 Vector Mapped'].tolist())
cvss_3_1_df = pd.DataFrame(data_filtered['CVSS 3.1 Vector Mapped'].tolist())
cvss_2_0_df.index = data_filtered.index
cvss_3_1_df.index = data_filtered.index

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(cvss_2_0_df, cvss_3_1_df, test_size=0.2, random_state=42)

# Verificar si hay datos nulos en los conjuntos de entrenamiento y prueba
print("X_train nulos:", X_train.isnull().sum().sum())
print("y_train nulos:", y_train.isnull().sum().sum())
print("X_test nulos:", X_test.isnull().sum().sum())
print("y_test nulos:", y_test.isnull().sum().sum())

# Definir una función de scoring personalizada para GridSearchCV
def custom_scorer(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    return 100 - (mae / (y_true.max() - y_true.min()) * 100)

scorer = make_scorer(custom_scorer, greater_is_better=True)

# Definir los modelos y los parámetros para GridSearchCV
models = {
    'LinearRegression': LinearRegression(),
    'RandomForest': RandomForestRegressor(),
    'GradientBoosting': GradientBoostingRegressor(),
    'kNN': KNeighborsRegressor()
}

params = {
    'LinearRegression': {},
    'RandomForest': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},
    'GradientBoosting': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2]},
    'kNN': {'n_neighbors': [5, 10, 20], 'weights': ['uniform', 'distance']}
}

best_models = {}
results = []

# Entrenar y evaluar cada modelo usando GridSearchCV y validación cruzada para cada columna de y_train
columns = ['AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']

for col in range(y_train.shape[1]):
    y_train_col = y_train.iloc[:, col]
    y_test_col = y_test.iloc[:, col]
    for name, model in models.items():
        print(f"Training {name} for target column {columns[col]}...")
        grid = GridSearchCV(model, params[name], cv=5, scoring=scorer, n_jobs=7)
        grid.fit(X_train, y_train_col)
        best_models[f"{name}_col{col}"] = grid.best_estimator_
        print(f"Best params for {name} (target column {columns[col]}): {grid.best_params_}")
        print(f"Best score for {name} (target column {columns[col]}): {grid.best_score_}")

# Evaluar los mejores modelos en el conjunto de prueba para cada columna
for col in range(y_test.shape[1]):
    y_test_col = y_test.iloc[:, col]
    for name in models.keys():
        model = best_models[f"{name}_col{col}"]
        predictions = model.predict(X_test)
        mae = mean_absolute_error(y_test_col, predictions)
        accuracy = 100 - (mae / (y_test_col.max() - y_test_col.min()) * 100)
        results.append({
            'Modelo': name,
            'Componente': columns[col],
            'MAE': mae,
            'Porcentaje de acierto': accuracy
        })
        print(f'Modelo: {name}, Target Column: {columns[col]}, MAE: {mae:.4f}, Porcentaje de acierto: {accuracy:.2f}%')

# Guardar los resultados en un CSV
results_df = pd.DataFrame(results)
results_df.to_csv('model_results.csv', index=False)

# Guardar los modelos entrenados en un archivo .pkl
joblib.dump(best_models, 'best_models.pkl')
