import pandas as pd
import joblib
import psycopg2
from psycopg2 import sql
from sklearn.compose import ColumnTransformer
from src.config.config import *

# Función para extraer y mapear los vectores CVSS a sus componentes
def extract_cvss_components(cvss_vector):
    if pd.isna(cvss_vector) or cvss_vector == 'N/A':
        return {}
    components = cvss_vector.split('/')
    components_dict = {}
    for comp in components:
        key, value = comp.split(':')
        components_dict[key] = value
    return components_dict

# Conexión a la base de datos
print("Connecting to the database...")
conn = psycopg2.connect(
    dbname=DB_NAME,
    user=DB_USER,
    password=DB_PASSWORD,
    host=DB_HOST,
    port=DB_PORT
)

# Crear un cursor
cur = conn.cursor()

# Leer los datos de la tabla 'scan_results'
query = "SELECT result_id,cvss_type, cvss_vector FROM scan_results"
df = pd.read_sql(query, conn)

# Filtrar los CVEs que tienen vectores CVSS 2.0 no nulos y no sean 'N/A'
cvss2_df = df[(df['cvss_type'] == 'cvss_base_v2') & ~df['cvss_vector'].isna() & (df['cvss_vector'] != 'N/A')]

# Filtrar los CVEs que ya tienen vectores CVSS 3.0/3.1
cvss3_df = df[df['cvss_type'] == 'cvss_base_v3']

# Cargar el modelo entrenado, los codificadores de etiquetas y el ColumnTransformer
best_models, label_encoders, column_transformer = joblib.load('src/models/best_models_classification.pkl')

# Lista para almacenar los resultados convertidos
converted_cves = []

# Columnas del vector CVSS 3.1
cvss_3_1_columns = ['AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']

# Iterar sobre cada CVE con vector CVSS 2.0
for _, row in cvss2_df.iterrows():
    vector_2_0 = row['cvss_vector']
    components_2_0 = extract_cvss_components(vector_2_0)
    input_df = pd.DataFrame([components_2_0])
    
    # Transformar las características de entrada
    input_transformed = column_transformer.transform(input_df)
    
    # Realizar la predicción para cada componente del vector CVSS 3.1
    predicted_vector_3_1 = {}
    for col in cvss_3_1_columns:
        model_key = [key for key in best_models.keys() if key.endswith(f"_col_{col}")]
        if model_key:
            model = best_models[model_key[0]]
            le = label_encoders[col]
            
            # Realizar la predicción
            prediction_encoded = model.predict(input_transformed)[0]
            prediction = le.inverse_transform([prediction_encoded])[0]
            predicted_vector_3_1[col] = prediction
        else:
            print(f"Modelo para {col} no encontrado en best_models.")
    
    # Formatear el resultado predicho
    formatted_output = '/'.join([f"{col}:{predicted_vector_3_1[col]}" for col in cvss_3_1_columns])
    
    # Añadir el CVE con el vector CVSS 3.1 convertido
    row['cvss_type'] = 'cvss_base_v3'  # Actualizar la base CVSS a 3.1
    row['cvss_vector'] = formatted_output
    converted_cves.append(row)

# Crear un DataFrame con los CVEs convertidos
converted_cves_df = pd.DataFrame(converted_cves)

# Concatenar los CVEs convertidos con los que ya tienen vectores CVSS 3.0/3.1
final_cves_df = pd.concat([converted_cves_df, cvss3_df])

# Actualizar la base de datos con los vectores CVSS 3.1 convertidos
with conn.cursor() as cursor:
    for _, row in converted_cves_df.iterrows():
        cursor.execute(
            sql.SQL("UPDATE scan_results SET cvss_type = %s, cvss_vector = %s WHERE result_id = %s"),
            [row['cvss_type'], row['cvss_vector'], row['result_id']]
        )
    conn.commit()

# Cerrar la conexión
conn.close()
